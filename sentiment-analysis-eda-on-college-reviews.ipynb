{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-14T05:33:18.230068Z","iopub.execute_input":"2023-08-14T05:33:18.230472Z","iopub.status.idle":"2023-08-14T05:33:18.275119Z","shell.execute_reply.started":"2023-08-14T05:33:18.230438Z","shell.execute_reply":"2023-08-14T05:33:18.274217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CR2021 = pd.read_csv('/kaggle/input/indian-college-reviews/collegereview2021.csv')","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:34:33.396463Z","iopub.execute_input":"2023-08-14T05:34:33.396981Z","iopub.status.idle":"2023-08-14T05:34:33.935175Z","shell.execute_reply.started":"2023-08-14T05:34:33.396937Z","shell.execute_reply":"2023-08-14T05:34:33.933997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CR2021.sample(20)","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:34:42.820621Z","iopub.execute_input":"2023-08-14T05:34:42.821166Z","iopub.status.idle":"2023-08-14T05:34:42.856523Z","shell.execute_reply.started":"2023-08-14T05:34:42.821117Z","shell.execute_reply":"2023-08-14T05:34:42.855348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CR2021.info()","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:34:49.19572Z","iopub.execute_input":"2023-08-14T05:34:49.196308Z","iopub.status.idle":"2023-08-14T05:34:49.252793Z","shell.execute_reply.started":"2023-08-14T05:34:49.196259Z","shell.execute_reply":"2023-08-14T05:34:49.251628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CR2021.describe()","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:34:57.940046Z","iopub.execute_input":"2023-08-14T05:34:57.940443Z","iopub.status.idle":"2023-08-14T05:34:57.969243Z","shell.execute_reply.started":"2023-08-14T05:34:57.940412Z","shell.execute_reply":"2023-08-14T05:34:57.96815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CR2021.shape","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:35:03.720063Z","iopub.execute_input":"2023-08-14T05:35:03.720481Z","iopub.status.idle":"2023-08-14T05:35:03.730517Z","shell.execute_reply.started":"2023-08-14T05:35:03.720446Z","shell.execute_reply":"2023-08-14T05:35:03.728961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CR2021.nunique()","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:35:44.220418Z","iopub.execute_input":"2023-08-14T05:35:44.220834Z","iopub.status.idle":"2023-08-14T05:35:44.282195Z","shell.execute_reply.started":"2023-08-14T05:35:44.220801Z","shell.execute_reply":"2023-08-14T05:35:44.280609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Assuming 'data' is your DataFrame containing the reviews and ratings\nsns.histplot(CR2021['rating'], bins=10, kde=True)\nplt.xlabel('Ratings')\nplt.ylabel('Frequency')\nplt.title('Distribution of Ratings')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:37:01.637194Z","iopub.execute_input":"2023-08-14T05:37:01.637659Z","iopub.status.idle":"2023-08-14T05:37:02.933617Z","shell.execute_reply.started":"2023-08-14T05:37:01.637616Z","shell.execute_reply":"2023-08-14T05:37:02.932284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport nltk\nimport re\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom wordcloud import WordCloud,STOPWORDS\nfrom nltk.stem.snowball import SnowballStemmer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.svm import LinearSVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import hamming_loss\nfrom skmultilearn.problem_transform import BinaryRelevance\nfrom sklearn.naive_bayes import MultinomialNB\nfrom skmultilearn.problem_transform import ClassifierChain\nfrom skmultilearn.problem_transform import LabelPowerset","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:39:32.526734Z","iopub.execute_input":"2023-08-14T05:39:32.528252Z","iopub.status.idle":"2023-08-14T05:39:33.583641Z","shell.execute_reply.started":"2023-08-14T05:39:32.52818Z","shell.execute_reply":"2023-08-14T05:39:33.582514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Remove Stopwords\nstop_words = set(stopwords.words('english'))\n\n# function to remove stopwords\ndef remove_stopwords(text):\n    no_stopword_text = [w for w in text.split() if not w in stop_words]\n    return ' '.join(no_stopword_text)\n\n#Clean Text\ndef clean_text(text):\n    text = text.lower()\n    text = re.sub(\"[^a-zA-Z]\",\" \",text) \n    text = ' '.join(text.split()) \n    return text\n\n#stemming\nstemmer = SnowballStemmer(\"english\")\ndef stemming(sentence):\n    stemSentence = \"\"\n    for word in sentence.split():\n        stem = stemmer.stem(word)\n        stemSentence += stem\n        stemSentence += \" \"\n    stemSentence = stemSentence.strip()\n    return stemSentence\nCR2021['review'] = CR2021['review'].astype(str)\nCR2021['review']= CR2021['review'].apply(lambda x: remove_stopwords(x))\nCR2021['review'] = CR2021['review'].apply(lambda x:clean_text(x))\nCR2021['review'] = CR2021['review'].apply(stemming)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:40:18.600375Z","iopub.execute_input":"2023-08-14T05:40:18.60086Z","iopub.status.idle":"2023-08-14T05:40:52.357041Z","shell.execute_reply.started":"2023-08-14T05:40:18.600819Z","shell.execute_reply":"2023-08-14T05:40:52.355997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from wordcloud import WordCloud\n\n# Concatenate all reviews into a single string\nall_reviews = ' '.join(CR2021['review'])\n\nwordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_reviews)\nplt.figure(figsize=(10, 5))\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis('off')\nplt.title('Word Cloud of Reviews')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:40:54.295277Z","iopub.execute_input":"2023-08-14T05:40:54.29568Z","iopub.status.idle":"2023-08-14T05:41:04.463739Z","shell.execute_reply.started":"2023-08-14T05:40:54.295647Z","shell.execute_reply":"2023-08-14T05:41:04.46232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# NLTK Sentiment Analysis:","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.sentiment import SentimentIntensityAnalyzer\n\nnltk.download('vader_lexicon')\n\n# Initialize SentimentIntensityAnalyzer\nsia = SentimentIntensityAnalyzer()\n\nCR2021['compound_score'] = CR2021['review'].apply(lambda x: sia.polarity_scores(x)['compound'])\n","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:45:22.550442Z","iopub.execute_input":"2023-08-14T05:45:22.550842Z","iopub.status.idle":"2023-08-14T05:45:46.848526Z","shell.execute_reply.started":"2023-08-14T05:45:22.550807Z","shell.execute_reply":"2023-08-14T05:45:46.847288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CR2021['compound_score']","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:45:46.850754Z","iopub.execute_input":"2023-08-14T05:45:46.85117Z","iopub.status.idle":"2023-08-14T05:45:46.862031Z","shell.execute_reply.started":"2023-08-14T05:45:46.851134Z","shell.execute_reply":"2023-08-14T05:45:46.860628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Training for Sentiment Analysis:","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n# Assuming you have a DataFrame 'df' with columns 'review_description' and 'rating'\nX = CR2021['review']\ny = CR2021['rating']\n\n# Convert ratings to binary sentiment labels (1 for positive, 0 for negative)\ny = (y > 3).astype(int)\n\n# Split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Create a Bag-of-Words representation of the text data\nvectorizer = CountVectorizer()\nX_train_vectorized = vectorizer.fit_transform(X_train)\nX_test_vectorized = vectorizer.transform(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:47:02.896218Z","iopub.execute_input":"2023-08-14T05:47:02.896666Z","iopub.status.idle":"2023-08-14T05:47:04.743545Z","shell.execute_reply.started":"2023-08-14T05:47:02.896628Z","shell.execute_reply":"2023-08-14T05:47:04.742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\n\n# Create and train the model\nmodel = MultinomialNB()\nmodel.fit(X_train_vectorized, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:47:13.121002Z","iopub.execute_input":"2023-08-14T05:47:13.121453Z","iopub.status.idle":"2023-08-14T05:47:13.156607Z","shell.execute_reply.started":"2023-08-14T05:47:13.121413Z","shell.execute_reply":"2023-08-14T05:47:13.155255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report\n\n# Make predictions on the testing data\ny_pred = model.predict(X_test_vectorized)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, y_pred)\nreport = classification_report(y_test, y_pred)\n\nprint(\"Accuracy:\", accuracy)\nprint(\"Classification Report:\\n\", report)","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:47:22.275895Z","iopub.execute_input":"2023-08-14T05:47:22.276381Z","iopub.status.idle":"2023-08-14T05:47:22.311221Z","shell.execute_reply.started":"2023-08-14T05:47:22.276342Z","shell.execute_reply":"2023-08-14T05:47:22.309145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_text = [\"The college of pretty decent\"]\nnew_text_vectorized = vectorizer.transform(new_text)","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:47:46.595995Z","iopub.execute_input":"2023-08-14T05:47:46.596481Z","iopub.status.idle":"2023-08-14T05:47:46.60266Z","shell.execute_reply.started":"2023-08-14T05:47:46.596441Z","shell.execute_reply":"2023-08-14T05:47:46.601207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_sentiment = model.predict(new_text_vectorized)\n\nif predicted_sentiment[0] == 1:\n    sentiment_label = \"Positive\"\nelse:\n    sentiment_label = \"Negative\"\n\nprint(\"Predicted Sentiment:\", sentiment_label)","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:47:55.476163Z","iopub.execute_input":"2023-08-14T05:47:55.47659Z","iopub.status.idle":"2023-08-14T05:47:55.484591Z","shell.execute_reply.started":"2023-08-14T05:47:55.476556Z","shell.execute_reply":"2023-08-14T05:47:55.483243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA using Pandas Profiler:","metadata":{}},{"cell_type":"code","source":"import ydata_profiling as pp\nimport seaborn as sns\nimport warnings\nimport os","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:48:34.650477Z","iopub.execute_input":"2023-08-14T05:48:34.650869Z","iopub.status.idle":"2023-08-14T05:48:37.230246Z","shell.execute_reply.started":"2023-08-14T05:48:34.650837Z","shell.execute_reply":"2023-08-14T05:48:37.228692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"pp.ProfileReport(CR2021)","metadata":{"execution":{"iopub.status.busy":"2023-08-14T05:48:47.006766Z","iopub.execute_input":"2023-08-14T05:48:47.007396Z","iopub.status.idle":"2023-08-14T05:49:15.577839Z","shell.execute_reply.started":"2023-08-14T05:48:47.007351Z","shell.execute_reply":"2023-08-14T05:49:15.576528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Note: In similar way we can do reviews of 2022 and 2023, Further EDA will be uploaded soon, Stay tuned! ","metadata":{}}]}